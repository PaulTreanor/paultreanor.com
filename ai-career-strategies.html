<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><meta name="description" content="My personal website where I keep my notes and thoughts."/><meta name="og:title" content="Paul Treanor"/><meta name="twitter:card" content="summary_large_image"/><link rel="alternate" type="application/rss+xml" title="RSS Feed for paultreanor.com" href="/rss.xml"/><title>Career directions in the age of AI</title><meta name="next-head-count" content="8"/><link rel="preload" href="/_next/static/css/f1fcd53e97c06bb4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f1fcd53e97c06bb4.css" data-n-g=""/><link rel="preload" href="/_next/static/css/d0f3a9e7dfd4b19b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d0f3a9e7dfd4b19b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-481ef0d25a716735.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1693ab7fc31cdd21.js" defer=""></script><script src="/_next/static/chunks/562-d0bcd15ec5190dc9.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bid%5D-331c202ad6dd6bd9.js" defer=""></script><script src="/_next/static/xu53aUgNH-xccAvmXOOZ3/_buildManifest.js" defer=""></script><script src="/_next/static/xu53aUgNH-xccAvmXOOZ3/_ssgManifest.js" defer=""></script></head><body><div id="__next"><script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script><script nomodule="" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script><div class="mx-2 md:mx-20 lg:mx-40 font-open-sans mb-32"><header class="max-w-2xl mx-auto"><div class="mt-10 mb-8"><a href="/"><div class="text-4xl">üè†</div></a></div></header><main><div class="max-w-2xl mx-auto"><h5 class="text-slate-600 font-normal mb-5"><time dateTime="2024-11-05">November 5, 2024</time></h5><div class="blog-content"><h1>Career directions in the age of AI</h1>
<p>I wanted to share some thoughts about how programmers might navigate the AI advancements that the next decade is going to bring. At the end of the day it's all just speculation really, but it's reassuring to have some personal direction.</p>
<p>My ideas around this assume that a few of my strongly held hunches around AI are true:</p>
<ol>
<li>AI is a <a href="https://en.wikipedia.org/wiki/General-purpose_technology">general-purpose technology</a> and a <a href="https://en.wikipedia.org/wiki/Megatrend">megatrend</a>, not a bubble.</li>
<li>AI will make all of software development, including the job market, more competitive.</li>
<li>Even if AI research stopped today, it would take decades to <a href="https://interconnected.org/home/2023/11/24/digestion">realise the full capabilities of current models</a>.</li>
</ol>
<h2>AI will disrupt tech domains unevenly</h2>
<p>I think AI agents will find some coding environments fairly easy to sandbox. It's already happening with <a href="https://www.anthropic.com/news/3-5-models-and-computer-use">browsers</a> and <a href="https://platform.openai.com/docs/assistants/tools/code-interpreter">REPL type scripting environments</a>, and it's easy to imagine container based apps being easy to replicate and test as well (because that's what containers were made for).</p>
<p>On the other hand intricate UIs, cloud systems, AI/VR environments, and embedded systems are going to be much harder for AI agents to sandbox. I don't think we'll have a general AI that can run effective tests on a wide range of embedded systems for a few decades (imagine a robot that can test hearing aids and ABS braking systems for lorries).</p>
<p>That makes learning C and assembly sound great but there's actually a massive trade-off here: if AI can't sandbox your job, then it can't really help you and speed you up either. If AI can sandbox your work environment then you are simply more replaceable. Working in domains that are easy to sandbox will have more opportunity because of growth, but they will also have  more risk.</p>
<p>The thing is AI advancements are unpredictable so the entire landscape could change in a few years. There's more value than ever in staying nimble and avoiding being pigeonholed.</p>
<h2>AI will make real craft more valuable</h2>
<p>LLMs are an immense advantage when writing code...but they almost makes it a little bit <em>too easy</em>, at the expense of <strong>understanding code and attention to detail</strong>. When <a href="https://github.com/fastai/fastai/pull/40480">AI is making it very easy to write a lot of slop</a>, holding yourself accountable for code is a differentiator.</p>
<p>Being precise is a requirement of being an engineer, we are paid because we understand what is going on under the hood - outsourcing this to AI is outsource your career. AI tools encourage moving fast and breaking things but mature software requires a certain level of discipline and craft. I think real craft in software is going to be a rare and valuable skill soon.</p>
<h2>Some technical skills will become more valuable</h2>
<p>Debugging is a bottleneck of coding assistant workflows right now. AI can write a lot of useful but buggy code, and then struggle to correct it. Being able to get to the root of the issues requires understanding protocols and frameworks one level deeper, and being being able to effectively use a debugger. These skills will become more valuable even as LLMs make programming more accessible.</p>
<p>Code review is gonna be more important too. Reading, understanding, and finding the edge cases in AI code is going to be central to the software engineer's job description in a few years. All this requires experience and a lot of patience.</p>
<p>While ChatGPT is a great code monkey I don't think it will be replacing system design and platform engineers. Architecting and provisioning cloud resources is fiddly, even if infrastructure by code is used. There's also just a lot more money at stake with big architecture decisions, so I expect management would prefer to have a human to hold accountable.</p>
<h2>Soft skills are going to be more valuable</h2>
<p>AI will end up doing a lot of work for us, but probably not work which requires real taste. It just can't write in a way that sounds compelling. <a href="https://www.linkedin.com/pulse/common-words-scream-ai-wrote-mukul-sharma-rawef">People can tell when they're reading AI generated slop</a> and it gives them the ick.</p>
<p>Good work is built on relationships with other people, and real social interactions with people can never be replaced by AI (although plenty of gouls trying to do just this üòî). ChatGPT just isn't capable of striking up and maintaining an actually interesting conversation on it's own. Even Claude can't take clients out for drinks and it probably won't get invited to the office Christmas party.</p>
<h2>Being really good at using AI is table stakes now</h2>
<p>One thing that I am certain of is that you <em>need</em> to keep your finger on the pulse of AI developments if you want to be a productive engineer. You need to be genuinely curious about applying AI to solve problems.</p>
<p>Here are some suggestions:</p>
<ul>
<li>Try out different tools/models to find strengths and weaknesses. There is no best model for <em>all</em> use cases.</li>
<li>Pay for access to the best tools/models, the ROI is x100.</li>
<li>Understand <a href="https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api">prompting 101</a>.</li>
<li>Understand that LLMs just generate text based on statistical probabilities in their training data. ChatGPT's "assistant" persona is created through prompts and RLHF. If you want coding help, ask it to be a senior dev instead of an assistant</li>
<li>Check in on and use the latest releases every few months.</li>
</ul>
<h2>Final thoughts</h2>
<p>Just in case this has freaked anyone out, please remember you are so much more than your work, but I don't think developers who can use AI effectively need to worry.</p></div></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"ai-career-strategies","contentHtml":"\u003ch1\u003eCareer directions in the age of AI\u003c/h1\u003e\n\u003cp\u003eI wanted to share some thoughts about how programmers might navigate the AI advancements that the next decade is going to bring. At the end of the day it's all just speculation really, but it's reassuring to have some personal direction.\u003c/p\u003e\n\u003cp\u003eMy ideas around this assume that a few of my strongly held hunches around AI are true:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAI is a \u003ca href=\"https://en.wikipedia.org/wiki/General-purpose_technology\"\u003egeneral-purpose technology\u003c/a\u003e and a \u003ca href=\"https://en.wikipedia.org/wiki/Megatrend\"\u003emegatrend\u003c/a\u003e, not a bubble.\u003c/li\u003e\n\u003cli\u003eAI will make all of software development, including the job market, more competitive.\u003c/li\u003e\n\u003cli\u003eEven if AI research stopped today, it would take decades to \u003ca href=\"https://interconnected.org/home/2023/11/24/digestion\"\u003erealise the full capabilities of current models\u003c/a\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eAI will disrupt tech domains unevenly\u003c/h2\u003e\n\u003cp\u003eI think AI agents will find some coding environments fairly easy to sandbox. It's already happening with \u003ca href=\"https://www.anthropic.com/news/3-5-models-and-computer-use\"\u003ebrowsers\u003c/a\u003e and \u003ca href=\"https://platform.openai.com/docs/assistants/tools/code-interpreter\"\u003eREPL type scripting environments\u003c/a\u003e, and it's easy to imagine container based apps being easy to replicate and test as well (because that's what containers were made for).\u003c/p\u003e\n\u003cp\u003eOn the other hand intricate UIs, cloud systems, AI/VR environments, and embedded systems are going to be much harder for AI agents to sandbox. I don't think we'll have a general AI that can run effective tests on a wide range of embedded systems for a few decades (imagine a robot that can test hearing aids and ABS braking systems for lorries).\u003c/p\u003e\n\u003cp\u003eThat makes learning C and assembly sound great but there's actually a massive trade-off here: if AI can't sandbox your job, then it can't really help you and speed you up either. If AI can sandbox your work environment then you are simply more replaceable. Working in domains that are easy to sandbox will have more opportunity because of growth, but they will also have  more risk.\u003c/p\u003e\n\u003cp\u003eThe thing is AI advancements are unpredictable so the entire landscape could change in a few years. There's more value than ever in staying nimble and avoiding being pigeonholed.\u003c/p\u003e\n\u003ch2\u003eAI will make real craft more valuable\u003c/h2\u003e\n\u003cp\u003eLLMs are an immense advantage when writing code...but they almost makes it a little bit \u003cem\u003etoo easy\u003c/em\u003e, at the expense of \u003cstrong\u003eunderstanding code and attention to detail\u003c/strong\u003e. When \u003ca href=\"https://github.com/fastai/fastai/pull/40480\"\u003eAI is making it very easy to write a lot of slop\u003c/a\u003e, holding yourself accountable for code is a differentiator.\u003c/p\u003e\n\u003cp\u003eBeing precise is a requirement of being an engineer, we are paid because we understand what is going on under the hood - outsourcing this to AI is outsource your career. AI tools encourage moving fast and breaking things but mature software requires a certain level of discipline and craft. I think real craft in software is going to be a rare and valuable skill soon.\u003c/p\u003e\n\u003ch2\u003eSome technical skills will become more valuable\u003c/h2\u003e\n\u003cp\u003eDebugging is a bottleneck of coding assistant workflows right now. AI can write a lot of useful but buggy code, and then struggle to correct it. Being able to get to the root of the issues requires understanding protocols and frameworks one level deeper, and being being able to effectively use a debugger. These skills will become more valuable even as LLMs make programming more accessible.\u003c/p\u003e\n\u003cp\u003eCode review is gonna be more important too. Reading, understanding, and finding the edge cases in AI code is going to be central to the software engineer's job description in a few years. All this requires experience and a lot of patience.\u003c/p\u003e\n\u003cp\u003eWhile ChatGPT is a great code monkey I don't think it will be replacing system design and platform engineers. Architecting and provisioning cloud resources is fiddly, even if infrastructure by code is used. There's also just a lot more money at stake with big architecture decisions, so I expect management would prefer to have a human to hold accountable.\u003c/p\u003e\n\u003ch2\u003eSoft skills are going to be more valuable\u003c/h2\u003e\n\u003cp\u003eAI will end up doing a lot of work for us, but probably not work which requires real taste. It just can't write in a way that sounds compelling. \u003ca href=\"https://www.linkedin.com/pulse/common-words-scream-ai-wrote-mukul-sharma-rawef\"\u003ePeople can tell when they're reading AI generated slop\u003c/a\u003e and it gives them the ick.\u003c/p\u003e\n\u003cp\u003eGood work is built on relationships with other people, and real social interactions with people can never be replaced by AI (although plenty of gouls trying to do just this üòî). ChatGPT just isn't capable of striking up and maintaining an actually interesting conversation on it's own. Even Claude can't take clients out for drinks and it probably won't get invited to the office Christmas party.\u003c/p\u003e\n\u003ch2\u003eBeing really good at using AI is table stakes now\u003c/h2\u003e\n\u003cp\u003eOne thing that I am certain of is that you \u003cem\u003eneed\u003c/em\u003e to keep your finger on the pulse of AI developments if you want to be a productive engineer. You need to be genuinely curious about applying AI to solve problems.\u003c/p\u003e\n\u003cp\u003eHere are some suggestions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTry out different tools/models to find strengths and weaknesses. There is no best model for \u003cem\u003eall\u003c/em\u003e use cases.\u003c/li\u003e\n\u003cli\u003ePay for access to the best tools/models, the ROI is x100.\u003c/li\u003e\n\u003cli\u003eUnderstand \u003ca href=\"https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api\"\u003eprompting 101\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eUnderstand that LLMs just generate text based on statistical probabilities in their training data. ChatGPT's \"assistant\" persona is created through prompts and RLHF. If you want coding help, ask it to be a senior dev instead of an assistant\u003c/li\u003e\n\u003cli\u003eCheck in on and use the latest releases every few months.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eFinal thoughts\u003c/h2\u003e\n\u003cp\u003eJust in case this has freaked anyone out, please remember you are so much more than your work, but I don't think developers who can use AI effectively need to worry.\u003c/p\u003e","title":"Career directions in the age of AI","short":"My thoughts on how software developers should direct their careers as we transition into the age of AI","date":"2024-11-05","slug":"ai-career-strategies","createdAt":"2024-11-05","img":"blog-2.jpg","tags":["Essay"]}},"__N_SSG":true},"page":"/[id]","query":{"id":"ai-career-strategies"},"buildId":"xu53aUgNH-xccAvmXOOZ3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>